#!/usr/bin/env python

from bs4 import BeautifulSoup
from bs4.element import Tag
from utilities import BASE_DIR
import json
import os.path
import time
# This code is designed directly from the Beautiful Soup documentation
# https://www.crummy.com/software/BeautifulSoup/bs4/doc/

def parse_courses(processed_path):
	parsed = []
	topics = []
	count = 0
	for i in range(22):
		file_name = "reut2-0"
		if i < 10:
			file_name += "0"
		file_name += str(i) + ".sgm"
		print(file_name)
		with open(BASE_DIR + '/raw/reuters21578/' + file_name) as file:
			soup = BeautifulSoup(file, features='html.parser')
			docs = soup.find_all('reuters')
			for doc in docs:
				# Creates item with autogenerated document id
				item = {'id': count}
				topic = {'id': count, 'assigned': False}
				if doc.attrs['topics'] == 'YES':
					topic['assigned'] = True
					topic['topics'] = []
					for topic_item in doc.find('topics'):
						topic['topics'].append(topic_item.string)
				text = doc.find('text')
				title = text.find('title')
				body = text.find('body')
				if title:
					item['title'] = title.string
				if body:
					item['body'] = body.string
				if 'title' in item and 'body' in item:
					parsed.append(item)
					topics.append(topic)
					count += 1

	# JSON write from https://stackoverflow.com/questions/12309269/how-do-i-write-json-data-to-a-file/20776329#20776329
	with open(processed_path + 'preprocessed.json', 'w') as outfile:
		json.dump(parsed, outfile, indent = 2, ensure_ascii = False)
	with open(processed_path + 'topics.json', 'w') as outfile:
		json.dump(topics, outfile, indent = 2, ensure_ascii = False)


# Throw error if file already generated
processed_path = BASE_DIR + "/processed/reuters/"
if not os.path.isfile(processed_path):
	parse_courses(processed_path)
else:
	print('FILE ALREADY GENERATED')